{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DGKDWZv4QwWh"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from tensorflow.keras import applications\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train='D:/Final/Graduation project/datasets/casting_data/casting_data/train'\n",
        "test='D:/Final/Graduation project/datasets/casting_data/casting_data/test'\n",
        "class_names = ['def_front', 'ok_front']\n",
        "folder_names = ['def_aug', 'ok_aug']\n",
        "class_to_folder = dict(zip(range(len(class_names)), folder_names))\n",
        "batch_size = 32\n",
        "img_size = (224, 224)"
      ],
      "metadata": {
        "id": "BP9Tl4BeQ1Ji"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator(rescale=1/255.0,\n",
        "                            rotation_range=20,\n",
        "                            zoom_range=0.05,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            validation_split=0.20)\n",
        "\n",
        "train_generator = trdata.flow_from_directory(directory=train_dir,\n",
        "                                              target_size=img_size,\n",
        "                                              subset='training',\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              color_mode='rgb',\n",
        "                                              class_mode='categorical',\n",
        "                                              save_to_dir=train,\n",
        "                                              classes=class_names)\n",
        "\n",
        "tsdata = ImageDataGenerator(rescale=1/255.0)\n",
        "test_generator = tsdata.flow_from_directory(directory=test_dir,\n",
        "                                             target_size=img_size,\n",
        "                                             color_mode='rgb',\n",
        "                                             batch_size=batch_size,\n",
        "                                             class_mode=None,\n",
        "                                             shuffle=False,\n",
        "                                             save_to_dir=test,\n",
        "                                             classes=class_names)\n",
        "\n",
        "valid_generator = trdata.flow_from_directory(directory=train,\n",
        "                                              target_size=(224, 224),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32 ,\n",
        "                                              class_mode='categorical',\n",
        "                                              subset='validation',\n",
        "                                              shuffle=True,\n",
        "                                              ).repeat()\n",
        "#it will generate 30* 32 image\n",
        "num_images_to_generate = 30\n",
        "for i in range(num_images_to_generate):\n",
        "    batch = train_generator.next()\n",
        "    for j in range(batch_size):\n",
        "        img = batch[0][j]\n",
        "        label = batch[1][j]\n",
        "        class_index = tf.argmax(label).numpy()\n",
        "        folder_path = os.path.join(train, 'def_front' if label[0] == 1 else 'ok_front')\n",
        "        save_path = os.path.join(folder_path, f'{class_to_folder[class_index]}_{i}.jpg')\n",
        "        tf.keras.preprocessing.image.save_img(save_path, img)\n",
        "\n",
        "for i in range(num_images_to_generate):\n",
        "    batch = test_generator.next()\n",
        "    for j in range(batch_size):\n",
        "        img = batch[0][j]\n",
        "        label = batch[1][j]\n",
        "        class_index = tf.argmax(label).numpy()\n",
        "        folder_path = os.path.join(test, 'def_front' if label[0] == 1 else 'ok_front')\n",
        "        save_path = os.path.join(folder_path, f'{class_to_folder[class_index]}_{i}.jpg')\n",
        "        tf.keras.preprocessing.image.save_img(save_path, img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "2sYuYSYpQ8ID",
        "outputId": "6b2304f7-c4b0-4f21-db11-f7ec25b48547"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ee9ed1fdd8c4>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                             validation_split=0.20)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m train_generator = trdata.flow_from_directory(directory=train_dir,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                               \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                               \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG = keras.applications.vgg16.VGG16(input_shape=(224,224,3), include_top = False, weights='imagenet')"
      ],
      "metadata": {
        "id": "JPjuXLjmRBC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG.trainable = False\n",
        "#Not train the front 13 layers, train only last two layers"
      ],
      "metadata": {
        "id": "ewvcrcihSP0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    VGG,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=256, activation=\"relu\"),\n",
        "    keras.layers.Dense(units=256, activation=\"relu\"),\n",
        "    keras.layers.Dense(units=2, activation=\"softmax\"), \n",
        "])"
      ],
      "metadata": {
        "id": "QjEpaxCvSTZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6ZO8NBJ-SVTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(traindata , steps_per_epoch = 195   , epochs = 5 , #traindata.n \n",
        "                           validation_data = valid_generator, validation_steps = 48)\n",
        "model.save('vggclf_v5.h5')\n",
        "\n",
        "\n",
        "# Your input ran out of data; interrupting training. Make sure that your \n",
        "#dataset or generator can generate at least `steps_per_epoch * epochs` batches \n",
        "# image data generator should generate at least 195*10 = 1950 so if i set batch size to 32 so i need a \n",
        "# 6230 / 32 = 195 batch to go through entire data set  "
      ],
      "metadata": {
        "id": "DjddvcfxSX3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(valid_generator,steps=48)"
      ],
      "metadata": {
        "id": "6jJwGdgESckG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BCrr1otjSf38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(testdata,steps = testdata.n, verbose = 1)\n",
        "\n",
        "pred"
      ],
      "metadata": {
        "id": "pjpyAThhSiRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "img = keras.utils.load_img(\"D:/Final/Graduation project/datasets/12.png\",target_size=(224,224))\n",
        "img = np.asarray(img)\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "img = np.expand_dims(img, axis=0)"
      ],
      "metadata": {
        "id": "xZSbHsaISkWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "saved_model = load_model(\"vggclf_v5.h5\")\n",
        "output = model.predict(img)\n",
        "if output[0][0] > output[0][1]:\n",
        "    print(\"defected\")\n",
        "    print(output)\n",
        "else:\n",
        "    print(\"good\")\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "w_qd7BflSnG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "  \n",
        "# Save the trained model as a pickle string.\n",
        "saved_model = pickle.dumps(model)\n",
        "model_from_pickle = pickle.loads(saved_model)"
      ],
      "metadata": {
        "id": "j6qBE3nNSpBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZCTmMBHSquG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}