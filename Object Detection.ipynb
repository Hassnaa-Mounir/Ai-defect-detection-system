{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqzuKJqbUCX2"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "metadata": {
        "id": "-rgVQxR3UjBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "metadata": {
        "id": "IXYtsiPVUooF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "metadata": {
        "id": "aGyVkhNNUssf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}\n",
        "            "
      ],
      "metadata": {
        "id": "pSiYAZ5XUvT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "metadata": {
        "id": "68Vd5v14U0rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "metadata": {
        "id": "fegyI1eLU45t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yRa-6EnVFNc",
        "outputId": "05427f86-0910-4918-c278-4001dcb058e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.46.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (0.6.0.post1)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (1.4.4)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.4-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.31.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.13.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.3)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.4)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.9/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (2.27.1)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.8-cp39-cp39-manylinux_2_28_x86_64.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (1.51.3)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.5/515.5 KB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (4.39.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_io->object-detection==0.1) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->object-detection==0.1) (3.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.65.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (67.6.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697012 sha256=30db7d173622ef376d361964e2c33fb34d5c28a542aed49dceb7e8000ae046e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p8jxdx6t/wheels/13/dc/b4/ca25040453ba296d853cb0ccf7c827a599f84e993647b41f42\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44008 sha256=9a88f4c8ad4eb419eb2694fe296f6b82b576648ca15325fc44ba2f1467547349\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/29/4d/510c0e098c49c5e49519f430481a5425e60b8752682d7b1e55\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=36926 sha256=f74d9ac03a60f5902a626283b5a647e0b1b212318f1b10f727e1f9555fb48418\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=a2f15c2c1887a62473bf01ceb3bf469069b6ffca5219409f443ab94ef8bceb41\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/0b/ce/75d96dd714b15e51cb66db631183ea3844e0c4a6d19741a149\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=8be18e4df69d49f6671bd52e7c050daf27d87c9fbd01c58b8a5ee937c7a3b5c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=a87c14065c087084d3de2dec31148c157983dde95dcbe73ec7b87202d02d943b\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built object-detection avro-python3 crcmod dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, crcmod, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, typeguard, sacrebleu, hdfs, tensorflow-addons, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "Successfully installed apache-beam-2.46.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.3 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.8 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.31.0 tf-models-official-2.11.4 tf-slim-1.1.0 typeguard-3.0.2 zstandard-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16bze6LgVT9X",
        "outputId": "bbc3aeba-01cf-423c-858a-5fb7729b736f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 11:44:29.072099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-23 11:44:30.384302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 11:44:30.384453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 11:44:30.384479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-23 11:44:35.332159: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.9.16: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W0323 11:44:35.994240 140550306330432 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.96s\n",
            "I0323 11:44:37.292517 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.96s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.89s\n",
            "I0323 11:44:40.199239 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.89s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 2.12s\n",
            "I0323 11:44:42.316202 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 2.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.26s\n",
            "I0323 11:44:43.574734 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.68s\n",
            "I0323 11:44:48.259294 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0323 11:44:48.267137 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0323 11:44:48.303474 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0323 11:44:48.325765 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0323 11:44:48.350540 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
            "I0323 11:44:48.498014 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "I0323 11:44:48.635888 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "I0323 11:44:48.769382 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I0323 11:44:48.909055 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "I0323 11:44:49.037374 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0323 11:44:49.076145 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0323 11:44:49.525474 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0323 11:44:49.525675 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0323 11:44:49.525734 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0323 11:44:49.528853 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:49.563782 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:49.563974 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:49.668151 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:49.668350 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:49.940048 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:49.940292 140550306330432 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0323 11:44:50.198366 140550306330432 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0323 11:44:50.198568 140550306330432 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0323 11:44:50.584477 140550306330432 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0323 11:44:50.584702 140550306330432 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0323 11:44:50.978544 140550306330432 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0323 11:44:50.978765 140550306330432 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0323 11:44:51.535088 140550306330432 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0323 11:44:51.535323 140550306330432 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0323 11:44:51.672466 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0323 11:44:51.753829 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:44:51.820368 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0323 11:44:51.820580 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0323 11:44:51.820663 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0323 11:44:51.822718 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:51.845625 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:51.845840 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:52.027272 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:52.027484 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:52.372266 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:52.372477 140550306330432 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0323 11:44:52.727158 140550306330432 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0323 11:44:52.727363 140550306330432 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0323 11:44:53.188001 140550306330432 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0323 11:44:53.188233 140550306330432 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0323 11:44:53.687369 140550306330432 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0323 11:44:53.687590 140550306330432 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0323 11:44:54.361874 140550306330432 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0323 11:44:54.362094 140550306330432 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0323 11:44:54.673835 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0323 11:44:54.751676 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:44:54.825299 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0323 11:44:54.825513 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0323 11:44:54.825573 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0323 11:44:54.827654 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:54.852118 140550306330432 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0323 11:44:54.852321 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:55.034475 140550306330432 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0323 11:44:55.034686 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:55.377325 140550306330432 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0323 11:44:55.377550 140550306330432 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0323 11:44:55.767140 140550306330432 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0323 11:44:55.767352 140550306330432 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0323 11:44:56.371711 140550306330432 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0323 11:44:56.371961 140550306330432 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0323 11:44:57.039177 140550306330432 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0323 11:44:57.039422 140550306330432 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0323 11:44:58.340284 140550306330432 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0323 11:44:58.340532 140550306330432 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0323 11:44:58.837881 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0323 11:44:58.976944 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:44:59.101034 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0323 11:44:59.104004 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0323 11:44:59.106196 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0323 11:44:59.110014 140550306330432 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0323 11:44:59.153447 140550306330432 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0323 11:44:59.153702 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:44:59.465851 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:44:59.466124 140550306330432 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0323 11:45:00.001563 140550306330432 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0323 11:45:00.001795 140550306330432 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0323 11:45:00.530462 140550306330432 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0323 11:45:00.530719 140550306330432 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0323 11:45:01.441693 140550306330432 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0323 11:45:01.441947 140550306330432 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0323 11:45:02.431926 140550306330432 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0323 11:45:02.432211 140550306330432 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0323 11:45:03.723972 140550306330432 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0323 11:45:03.724269 140550306330432 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0323 11:45:04.294350 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0323 11:45:04.441785 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:45:04.582365 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0323 11:45:04.582627 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0323 11:45:04.582739 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0323 11:45:04.586011 140550306330432 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0323 11:45:04.623957 140550306330432 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0323 11:45:04.624258 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:45:04.841395 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:45:04.841603 140550306330432 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0323 11:45:05.328505 140550306330432 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0323 11:45:05.328736 140550306330432 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0323 11:45:05.815674 140550306330432 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0323 11:45:05.815885 140550306330432 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0323 11:45:06.571167 140550306330432 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0323 11:45:06.571374 140550306330432 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0323 11:45:07.342124 140550306330432 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0323 11:45:07.342360 140550306330432 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0323 11:45:08.584917 140550306330432 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0323 11:45:08.585157 140550306330432 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0323 11:45:08.969309 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0323 11:45:09.086113 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:45:09.178510 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0323 11:45:09.178765 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0323 11:45:09.178868 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0323 11:45:09.181250 140550306330432 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0323 11:45:09.204319 140550306330432 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0323 11:45:09.204525 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:45:09.479472 140550306330432 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0323 11:45:09.479680 140550306330432 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0323 11:45:10.482597 140550306330432 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0323 11:45:10.482816 140550306330432 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0323 11:45:11.124799 140550306330432 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0323 11:45:11.125020 140550306330432 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0323 11:45:12.030534 140550306330432 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0323 11:45:12.030739 140550306330432 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0323 11:45:12.955544 140550306330432 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0323 11:45:12.955761 140550306330432 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0323 11:45:14.341694 140550306330432 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0323 11:45:14.341902 140550306330432 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0323 11:45:15.126724 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0323 11:45:15.293900 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:45:15.470061 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0323 11:45:15.470314 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0323 11:45:15.470402 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0323 11:45:15.473387 140550306330432 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0323 11:45:15.509551 140550306330432 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0323 11:45:15.509800 140550306330432 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0323 11:45:15.901475 140550306330432 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0323 11:45:15.901738 140550306330432 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0323 11:45:16.852107 140550306330432 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0323 11:45:16.852360 140550306330432 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0323 11:45:17.949863 140550306330432 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0323 11:45:17.950153 140550306330432 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0323 11:45:19.490436 140550306330432 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0323 11:45:19.490705 140550306330432 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0323 11:45:21.133724 140550306330432 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0323 11:45:21.133981 140550306330432 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0323 11:45:23.777651 140550306330432 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0323 11:45:23.777857 140550306330432 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0323 11:45:24.492466 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0323 11:45:24.616729 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0323 11:45:25.056783 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0323 11:45:25.056983 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0323 11:45:25.057044 140550306330432 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0323 11:45:25.059168 140550306330432 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0323 11:45:25.087918 140550306330432 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0323 11:45:25.088179 140550306330432 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0323 11:45:25.466463 140550306330432 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0323 11:45:25.466667 140550306330432 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0323 11:45:26.276539 140550306330432 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0323 11:45:26.276743 140550306330432 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0323 11:45:27.110325 140550306330432 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0323 11:45:27.110533 140550306330432 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0323 11:45:28.399815 140550306330432 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0323 11:45:28.400022 140550306330432 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0323 11:45:29.781523 140550306330432 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0323 11:45:29.781737 140550306330432 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0323 11:45:32.066403 140550306330432 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0323 11:45:32.066745 140550306330432 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0323 11:45:33.177207 140550306330432 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0323 11:45:33.311711 140550306330432 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.47s\n",
            "I0323 11:45:33.544691 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.47s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I0323 11:45:33.612739 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0323 11:45:33.615759 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0323 11:45:33.616558 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0323 11:45:33.619164 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0323 11:45:33.621451 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0323 11:45:33.622098 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0323 11:45:33.624827 140550306330432 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 58.290s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import object_detection"
      ],
      "metadata": {
        "id": "F5z85_TwV5Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViGXYF03V8dt",
        "outputId": "34187846-30c5-4b98-de5a-85399ceb7e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------------\n",
            "absl-py                       1.4.0\n",
            "alabaster                     0.7.13\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.2\n",
            "apache-beam                   2.46.0\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.15.1\n",
            "astropy                       5.2.1\n",
            "astunparse                    1.6.3\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.2.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.12.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.11.2\n",
            "bleach                        6.0.0\n",
            "blis                          0.7.9\n",
            "bokeh                         2.4.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.3.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.12.7\n",
            "cffi                          1.15.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.12\n",
            "click                         8.1.3\n",
            "cloudpickle                   2.2.1\n",
            "cmake                         3.25.2\n",
            "cmdstanpy                     1.1.0\n",
            "colorama                      0.4.6\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.4\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.6.0.post1\n",
            "contourpy                     1.0.7\n",
            "convertdate                   2.4.0\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.3.1\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.33\n",
            "dask                          2022.12.1\n",
            "datascience                   0.17.6\n",
            "db-dtypes                     1.0.5\n",
            "dbus-python                   1.2.16\n",
            "debugpy                       1.6.6\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "dill                          0.3.1.1\n",
            "distributed                   2022.12.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.8\n",
            "docopt                        0.6.2\n",
            "docutils                      0.16\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.345\n",
            "easydict                      1.10\n",
            "ecos                          2.0.12\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.5.0\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.4\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         1.1.1\n",
            "etuples                       0.3.8\n",
            "fastai                        2.7.11\n",
            "fastavro                      1.7.3\n",
            "fastcore                      1.5.28\n",
            "fastdownload                  0.0.7\n",
            "fasteners                     0.18\n",
            "fastjsonschema                2.16.3\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "filelock                      3.10.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         2.2.3\n",
            "flatbuffers                   23.3.3\n",
            "folium                        0.14.0\n",
            "fonttools                     4.39.2\n",
            "fsspec                        2023.3.0\n",
            "future                        0.18.3\n",
            "gast                          0.4.0\n",
            "GDAL                          3.3.2\n",
            "gdown                         4.6.4\n",
            "gensim                        4.3.1\n",
            "geographiclib                 2.0\n",
            "geopy                         2.3.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.11.0\n",
            "google-api-python-client      2.70.0\n",
            "google-auth                   2.16.2\n",
            "google-auth-httplib2          0.1.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.4.2\n",
            "google-cloud-bigquery-storage 2.19.0\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.11.1\n",
            "google-cloud-firestore        2.7.3\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.7.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.1\n",
            "googleapis-common-protos      1.58.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.20.1\n",
            "greenlet                      2.0.2\n",
            "grpcio                        1.51.3\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5netcdf                      1.1.0\n",
            "h5py                          3.8.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.21.13\n",
            "holoviews                     1.15.4\n",
            "html5lib                      1.1\n",
            "htmlmin                       0.1.12\n",
            "httpimport                    1.3.0\n",
            "httplib2                      0.21.0\n",
            "humanize                      4.6.0\n",
            "hyperopt                      0.2.7\n",
            "idna                          3.4\n",
            "ImageHash                     4.3.1\n",
            "imageio                       2.25.1\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.10.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "immutabledict                 2.2.3\n",
            "importlib-metadata            6.1.0\n",
            "importlib-resources           5.12.0\n",
            "imutils                       0.5.4\n",
            "inflect                       6.0.2\n",
            "intel-openmp                  2023.0.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  2.1.2\n",
            "jax                           0.4.6\n",
            "jaxlib                        0.4.6+cuda11.cudnn86\n",
            "jieba                         0.42.1\n",
            "Jinja2                        3.1.2\n",
            "joblib                        1.1.1\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter_core                  5.3.0\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            3.0.5\n",
            "kaggle                        1.5.13\n",
            "keras                         2.11.0\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "lazy_loader                   0.1\n",
            "libclang                      15.0.6.1\n",
            "librosa                       0.10.0.post2\n",
            "lightgbm                      3.3.5\n",
            "llvmlite                      0.39.1\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.2\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.1.2\n",
            "matplotlib                    3.7.1\n",
            "matplotlib-venn               0.11.9\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.2\n",
            "mistune                       0.8.4\n",
            "mizani                        0.8.1\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.1.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.3.0\n",
            "msgpack                       1.0.5\n",
            "multimethod                   1.9.1\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.7.2\n",
            "nbconvert                     6.5.4\n",
            "nbformat                      5.8.0\n",
            "networkx                      3.0\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.8.1\n",
            "notebook                      6.3.0\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.22.4\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "object-detection              0.1\n",
            "objsize                       0.6.1\n",
            "opencv-contrib-python         4.7.0.72\n",
            "opencv-python                 4.7.0.72\n",
            "opencv-python-headless        4.7.0.72\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.8.8\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     23.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.4.4\n",
            "pandas-datareader             0.10.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              3.2.0\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.14.4\n",
            "param                         1.13.0\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.1\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "phik                          0.12.3\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        8.4.0\n",
            "pip                           22.0.4\n",
            "pip-tools                     6.6.2\n",
            "platformdirs                  3.1.1\n",
            "plotly                        5.13.1\n",
            "plotnine                      0.10.1\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.7.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.6.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.16.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.2\n",
            "proto-plus                    1.22.2\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.9.4\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    9.0.0\n",
            "py4j                          0.10.9.7\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.5.0\n",
            "pydantic                      1.10.6\n",
            "pydata-google-auth            1.7.0\n",
            "pydot                         1.4.2\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyerfa                        2.0.0.2\n",
            "Pygments                      2.6.1\n",
            "PyGObject                     3.36.0\n",
            "pymc                          5.1.2\n",
            "PyMeeus                       0.5.12\n",
            "pymongo                       3.13.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.19.3\n",
            "PySocks                       1.7.1\n",
            "pytensor                      2.10.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                8.0.1\n",
            "python-utils                  3.5.2\n",
            "pytz                          2022.7.1\n",
            "pytz-deprecation-shim         0.1.0.post0\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post3\n",
            "qudida                        0.0.4\n",
            "regex                         2022.10.31\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.1\n",
            "requests-unixsocket           0.2.0\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-image                  0.19.3\n",
            "scikit-learn                  1.2.2\n",
            "scipy                         1.10.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.12.2\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    67.6.0\n",
            "shapely                       2.0.1\n",
            "six                           1.16.0\n",
            "sklearn-pandas                2.2.0\n",
            "smart-open                    6.3.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.12.1\n",
            "soupsieve                     2.4\n",
            "soxr                          0.3.4\n",
            "spacy                         3.5.1\n",
            "spacy-legacy                  3.0.12\n",
            "spacy-loggers                 1.0.4\n",
            "Sphinx                        3.5.4\n",
            "sphinxcontrib-applehelp       1.0.4\n",
            "sphinxcontrib-devhelp         1.0.2\n",
            "sphinxcontrib-htmlhelp        2.0.1\n",
            "sphinxcontrib-jsmath          1.0.1\n",
            "sphinxcontrib-qthelp          1.0.3\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "SQLAlchemy                    1.4.47\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.6\n",
            "statsmodels                   0.13.5\n",
            "sympy                         1.11.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tangled-up-in-unicode         0.2.0\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.2.2\n",
            "tensorboard                   2.11.2\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.11.0\n",
            "tensorflow-addons             0.19.0\n",
            "tensorflow-datasets           4.8.3\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-gcs-config         2.11.0\n",
            "tensorflow-hub                0.13.0\n",
            "tensorflow-io                 0.31.0\n",
            "tensorflow-io-gcs-filesystem  0.31.0\n",
            "tensorflow-metadata           1.12.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.19.0\n",
            "tensorflow-text               2.11.0\n",
            "termcolor                     2.2.0\n",
            "terminado                     0.17.1\n",
            "text-unidecode                1.3\n",
            "textblob                      0.17.1\n",
            "tf-models-official            2.11.4\n",
            "tf-slim                       1.1.0\n",
            "thinc                         8.1.9\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2023.3.15\n",
            "tinycss2                      1.2.1\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.1+cu116\n",
            "torchaudio                    0.13.1+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.14.1+cu116\n",
            "tornado                       6.2\n",
            "tqdm                          4.65.0\n",
            "traitlets                     5.7.1\n",
            "tweepy                        4.13.0\n",
            "typeguard                     3.0.2\n",
            "typer                         0.7.0\n",
            "typing_extensions             4.5.0\n",
            "tzdata                        2022.7\n",
            "tzlocal                       4.3\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.26.15\n",
            "vega-datasets                 0.9.0\n",
            "visions                       0.7.4\n",
            "wasabi                        1.1.1\n",
            "wcwidth                       0.2.6\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      2.2.3\n",
            "wheel                         0.40.0\n",
            "widgetsnbextension            3.6.2\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.15.0\n",
            "xarray                        2022.12.0\n",
            "xarray-einstats               0.5.1\n",
            "xgboost                       1.7.4\n",
            "xkit                          0.0.0\n",
            "xlrd                          2.0.1\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.15.0\n",
            "zstandard                     0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-P67uMDWjtu",
        "outputId": "c9fe2164-a266-4ea9-9411-c0b94d151acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-23 14:11:45--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.217.128, 2607:f8b0:400c:c13::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.217.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-23 14:11:46 (164 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'CastingProduct', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "1vVV2eywXJ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf /content/Tensorflow/workspace/images/archive.tar.gz"
      ],
      "metadata": {
        "id": "RvIkpDZ8XpZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "metadata": {
        "id": "ZYtleHMYalTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c1c80d-eb45-4315-97e7-5f35ce39cddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 2.67 KiB | 2.67 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXhQyYsJa7Lw",
        "outputId": "2e6b37b0-7559-46d6-f24e-9c333af126d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 11:45:43.854513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "2023-03-23 11:45:49.169099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "metadata": {
        "id": "ZngWPQOtbRXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "EYy5TYFNbZJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "y7MbZmEEbd-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "FCQ79utkbfz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13d3b41-63a0-46ee-c4c1-737fe08e8c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " }, 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "metadata": {
        "id": "oPPI5Tsmga2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "metadata": {
        "id": "5QQWEDWBgpyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "metadata": {
        "id": "a_XI6iWzgtCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model\n"
      ],
      "metadata": {
        "id": "yzSXL0riheFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "metadata": {
        "id": "2BJGiLgHhbOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "nw1b0Kb5hbUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "id": "sn79fSGThsnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1eb12b-f9d6-4bb6-9b25-8f252ef6aced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "id": "3GSt7TZ2hyE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69cadf1-ef33-4652-dde2-404ac303813b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 11:45:56.759513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 11:45:56.759679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 11:45:56.759709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-23 11:46:06.273699: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0323 11:46:06.275390 140535383660352 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0323 11:46:06.302457 140535383660352 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0323 11:46:06.307413 140535383660352 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0323 11:46:06.307609 140535383660352 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0323 11:46:06.340977 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0323 11:46:06.356997 140535383660352 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0323 11:46:06.357458 140535383660352 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0323 11:46:06.357602 140535383660352 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0323 11:46:06.357693 140535383660352 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0323 11:46:06.369448 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0323 11:46:06.394718 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0323 11:46:07.108509 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0323 11:46:14.246970 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0323 11:46:19.688202 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0323 11:46:23.320415 140535383660352 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2023-03-23 11:46:26.557117: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0323 11:46:32.664899 140532761474816 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0323 11:46:46.173038 140532761474816 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0323 11:46:56.468491 140532795045632 deprecation.py:554] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0323 11:46:58.397581 140532795045632 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0323 11:47:06.734380 140532795045632 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0323 11:47:14.273480 140532795045632 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0323 11:47:23.402280 140532795045632 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "INFO:tensorflow:Step 100 per-step time 2.865s\n",
            "I0323 11:51:42.282761 140535383660352 model_lib_v2.py:705] Step 100 per-step time 2.865s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.094358794,\n",
            " 'Loss/localization_loss': 0.048579607,\n",
            " 'Loss/regularization_loss': 0.15330091,\n",
            " 'Loss/total_loss': 0.29623932,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0323 11:51:42.283256 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.094358794,\n",
            " 'Loss/localization_loss': 0.048579607,\n",
            " 'Loss/regularization_loss': 0.15330091,\n",
            " 'Loss/total_loss': 0.29623932,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 2.340s\n",
            "I0323 11:55:36.314000 140535383660352 model_lib_v2.py:705] Step 200 per-step time 2.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11988471,\n",
            " 'Loss/localization_loss': 0.058422856,\n",
            " 'Loss/regularization_loss': 0.15295318,\n",
            " 'Loss/total_loss': 0.33126074,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0323 11:55:36.314538 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.11988471,\n",
            " 'Loss/localization_loss': 0.058422856,\n",
            " 'Loss/regularization_loss': 0.15295318,\n",
            " 'Loss/total_loss': 0.33126074,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 2.309s\n",
            "I0323 11:59:27.205540 140535383660352 model_lib_v2.py:705] Step 300 per-step time 2.309s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04591061,\n",
            " 'Loss/localization_loss': 0.009483396,\n",
            " 'Loss/regularization_loss': 0.15255275,\n",
            " 'Loss/total_loss': 0.20794676,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0323 11:59:27.205972 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.04591061,\n",
            " 'Loss/localization_loss': 0.009483396,\n",
            " 'Loss/regularization_loss': 0.15255275,\n",
            " 'Loss/total_loss': 0.20794676,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 2.379s\n",
            "I0323 12:03:25.150010 140535383660352 model_lib_v2.py:705] Step 400 per-step time 2.379s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04662415,\n",
            " 'Loss/localization_loss': 0.01622566,\n",
            " 'Loss/regularization_loss': 0.15208422,\n",
            " 'Loss/total_loss': 0.21493404,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0323 12:03:25.150466 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.04662415,\n",
            " 'Loss/localization_loss': 0.01622566,\n",
            " 'Loss/regularization_loss': 0.15208422,\n",
            " 'Loss/total_loss': 0.21493404,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 2.393s\n",
            "I0323 12:07:24.425933 140535383660352 model_lib_v2.py:705] Step 500 per-step time 2.393s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040967274,\n",
            " 'Loss/localization_loss': 0.009525483,\n",
            " 'Loss/regularization_loss': 0.15155001,\n",
            " 'Loss/total_loss': 0.20204276,\n",
            " 'learning_rate': 0.053333}\n",
            "I0323 12:07:24.426848 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.040967274,\n",
            " 'Loss/localization_loss': 0.009525483,\n",
            " 'Loss/regularization_loss': 0.15155001,\n",
            " 'Loss/total_loss': 0.20204276,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 2.354s\n",
            "I0323 12:11:19.796777 140535383660352 model_lib_v2.py:705] Step 600 per-step time 2.354s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044751815,\n",
            " 'Loss/localization_loss': 0.009378598,\n",
            " 'Loss/regularization_loss': 0.1509691,\n",
            " 'Loss/total_loss': 0.20509952,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0323 12:11:19.797239 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.044751815,\n",
            " 'Loss/localization_loss': 0.009378598,\n",
            " 'Loss/regularization_loss': 0.1509691,\n",
            " 'Loss/total_loss': 0.20509952,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 2.336s\n",
            "I0323 12:15:13.424060 140535383660352 model_lib_v2.py:705] Step 700 per-step time 2.336s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.071285844,\n",
            " 'Loss/localization_loss': 0.020415358,\n",
            " 'Loss/regularization_loss': 0.15030415,\n",
            " 'Loss/total_loss': 0.24200535,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0323 12:15:13.424635 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.071285844,\n",
            " 'Loss/localization_loss': 0.020415358,\n",
            " 'Loss/regularization_loss': 0.15030415,\n",
            " 'Loss/total_loss': 0.24200535,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 2.310s\n",
            "I0323 12:19:04.394536 140535383660352 model_lib_v2.py:705] Step 800 per-step time 2.310s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019849025,\n",
            " 'Loss/localization_loss': 0.0038621079,\n",
            " 'Loss/regularization_loss': 0.14962727,\n",
            " 'Loss/total_loss': 0.17333841,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0323 12:19:04.394944 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.019849025,\n",
            " 'Loss/localization_loss': 0.0038621079,\n",
            " 'Loss/regularization_loss': 0.14962727,\n",
            " 'Loss/total_loss': 0.17333841,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 2.356s\n",
            "I0323 12:23:00.020819 140535383660352 model_lib_v2.py:705] Step 900 per-step time 2.356s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03283131,\n",
            " 'Loss/localization_loss': 0.00738211,\n",
            " 'Loss/regularization_loss': 0.14888129,\n",
            " 'Loss/total_loss': 0.1890947,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0323 12:23:00.021319 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.03283131,\n",
            " 'Loss/localization_loss': 0.00738211,\n",
            " 'Loss/regularization_loss': 0.14888129,\n",
            " 'Loss/total_loss': 0.1890947,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 2.335s\n",
            "I0323 12:26:53.521483 140535383660352 model_lib_v2.py:705] Step 1000 per-step time 2.335s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041430775,\n",
            " 'Loss/localization_loss': 0.015901135,\n",
            " 'Loss/regularization_loss': 0.1480725,\n",
            " 'Loss/total_loss': 0.2054044,\n",
            " 'learning_rate': 0.08}\n",
            "I0323 12:26:53.521879 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.041430775,\n",
            " 'Loss/localization_loss': 0.015901135,\n",
            " 'Loss/regularization_loss': 0.1480725,\n",
            " 'Loss/total_loss': 0.2054044,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 2.339s\n",
            "I0323 12:30:47.476224 140535383660352 model_lib_v2.py:705] Step 1100 per-step time 2.339s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034796603,\n",
            " 'Loss/localization_loss': 0.009734048,\n",
            " 'Loss/regularization_loss': 0.14723095,\n",
            " 'Loss/total_loss': 0.1917616,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0323 12:30:47.476751 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.034796603,\n",
            " 'Loss/localization_loss': 0.009734048,\n",
            " 'Loss/regularization_loss': 0.14723095,\n",
            " 'Loss/total_loss': 0.1917616,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 2.395s\n",
            "I0323 12:34:47.000864 140535383660352 model_lib_v2.py:705] Step 1200 per-step time 2.395s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030895384,\n",
            " 'Loss/localization_loss': 0.0062617147,\n",
            " 'Loss/regularization_loss': 0.14635898,\n",
            " 'Loss/total_loss': 0.18351609,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0323 12:34:47.003274 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.030895384,\n",
            " 'Loss/localization_loss': 0.0062617147,\n",
            " 'Loss/regularization_loss': 0.14635898,\n",
            " 'Loss/total_loss': 0.18351609,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 2.353s\n",
            "I0323 12:38:42.348410 140535383660352 model_lib_v2.py:705] Step 1300 per-step time 2.353s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.023493228,\n",
            " 'Loss/localization_loss': 0.007017492,\n",
            " 'Loss/regularization_loss': 0.14550687,\n",
            " 'Loss/total_loss': 0.1760176,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0323 12:38:42.348939 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.023493228,\n",
            " 'Loss/localization_loss': 0.007017492,\n",
            " 'Loss/regularization_loss': 0.14550687,\n",
            " 'Loss/total_loss': 0.1760176,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 2.365s\n",
            "I0323 12:42:38.818759 140535383660352 model_lib_v2.py:705] Step 1400 per-step time 2.365s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025869178,\n",
            " 'Loss/localization_loss': 0.0065913387,\n",
            " 'Loss/regularization_loss': 0.14467077,\n",
            " 'Loss/total_loss': 0.17713128,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0323 12:42:38.819202 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.025869178,\n",
            " 'Loss/localization_loss': 0.0065913387,\n",
            " 'Loss/regularization_loss': 0.14467077,\n",
            " 'Loss/total_loss': 0.17713128,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 2.382s\n",
            "I0323 12:46:37.000132 140535383660352 model_lib_v2.py:705] Step 1500 per-step time 2.382s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044229414,\n",
            " 'Loss/localization_loss': 0.009478822,\n",
            " 'Loss/regularization_loss': 0.14381878,\n",
            " 'Loss/total_loss': 0.19752702,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0323 12:46:37.000557 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.044229414,\n",
            " 'Loss/localization_loss': 0.009478822,\n",
            " 'Loss/regularization_loss': 0.14381878,\n",
            " 'Loss/total_loss': 0.19752702,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 2.377s\n",
            "I0323 12:50:34.697161 140535383660352 model_lib_v2.py:705] Step 1600 per-step time 2.377s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038452405,\n",
            " 'Loss/localization_loss': 0.0076915487,\n",
            " 'Loss/regularization_loss': 0.14296642,\n",
            " 'Loss/total_loss': 0.18911037,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0323 12:50:34.697574 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.038452405,\n",
            " 'Loss/localization_loss': 0.0076915487,\n",
            " 'Loss/regularization_loss': 0.14296642,\n",
            " 'Loss/total_loss': 0.18911037,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 2.373s\n",
            "I0323 12:54:32.021575 140535383660352 model_lib_v2.py:705] Step 1700 per-step time 2.373s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03899588,\n",
            " 'Loss/localization_loss': 0.012680487,\n",
            " 'Loss/regularization_loss': 0.14211522,\n",
            " 'Loss/total_loss': 0.19379158,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0323 12:54:32.022005 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.03899588,\n",
            " 'Loss/localization_loss': 0.012680487,\n",
            " 'Loss/regularization_loss': 0.14211522,\n",
            " 'Loss/total_loss': 0.19379158,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 2.414s\n",
            "I0323 12:58:33.468487 140535383660352 model_lib_v2.py:705] Step 1800 per-step time 2.414s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027207127,\n",
            " 'Loss/localization_loss': 0.005934783,\n",
            " 'Loss/regularization_loss': 0.14127435,\n",
            " 'Loss/total_loss': 0.17441626,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0323 12:58:33.468902 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.027207127,\n",
            " 'Loss/localization_loss': 0.005934783,\n",
            " 'Loss/regularization_loss': 0.14127435,\n",
            " 'Loss/total_loss': 0.17441626,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 2.392s\n",
            "I0323 13:02:32.699937 140535383660352 model_lib_v2.py:705] Step 1900 per-step time 2.392s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01905324,\n",
            " 'Loss/localization_loss': 0.009302357,\n",
            " 'Loss/regularization_loss': 0.14043643,\n",
            " 'Loss/total_loss': 0.16879202,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0323 13:02:32.700613 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.01905324,\n",
            " 'Loss/localization_loss': 0.009302357,\n",
            " 'Loss/regularization_loss': 0.14043643,\n",
            " 'Loss/total_loss': 0.16879202,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 2.348s\n",
            "I0323 13:06:27.555347 140535383660352 model_lib_v2.py:705] Step 2000 per-step time 2.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027102863,\n",
            " 'Loss/localization_loss': 0.008569953,\n",
            " 'Loss/regularization_loss': 0.13960794,\n",
            " 'Loss/total_loss': 0.17528075,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0323 13:06:27.555889 140535383660352 model_lib_v2.py:708] {'Loss/classification_loss': 0.027102863,\n",
            " 'Loss/localization_loss': 0.008569953,\n",
            " 'Loss/regularization_loss': 0.13960794,\n",
            " 'Loss/total_loss': 0.17528075,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Tensorflow/workspace/models/my_ssd_mobnet /content/Tensorflow/workspace/models/my_ssd_mobnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDI7WTkFlc6Y",
        "outputId": "0871ea7d-a08b-443c-d204-d3b6902c6ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ (stored 0%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/train/ (stored 0%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/train/events.out.tfevents.1679571985.d63812902261.1341.0.v2 (deflated 1%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/ (stored 0%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-1.index (deflated 81%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-2.index (deflated 82%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport/ (stored 0%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3.index (deflated 82%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/export/ (stored 0%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-1.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/checkpoint (deflated 63%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config (deflated 69%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-2.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3.data-00000-of-00001 (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Tensorflow/workspace/models/my_ssd_mobnet.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8Jb-66X4mlhX",
        "outputId": "262632d7-9cec-49d4-d03f-588848c4aaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02f83a08-f2a8-4c5d-9e75-0211a69ce832\", \"my_ssd_mobnet.zip\", 52051939)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval percision"
      ],
      "metadata": {
        "id": "06tJ5Z2goSVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2aTT4KcpoAt",
        "outputId": "ef2d0112-f7c7-44db-99aa-98c7655f9df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dqNuIgbqKUP",
        "outputId": "d08ef5ef-803b-49f8-c2eb-cd152b92e6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd workspace/models/my_ssd_mobnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-msINgNqPOJ",
        "outputId": "28baf28b-f493-48d5-ac11-c429f075061d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tensorflow/workspace/models/my_ssd_mobnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyemWAvFqjIS",
        "outputId": "d1314867-b35c-4de4-9e8f-a8daa6cd29eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tensorflow/workspace/models/my_ssd_mobnet/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "3skU77nTwwBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFJRa1xxqltf",
        "outputId": "8c17418c-81f7-4145-c3ec-c37b3815af64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 13:58:47.717698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 13:58:47.717831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 13:58:47.717855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-23 13:58:49.487310: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Address already in use\n",
            "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Tensorflow/workspace/models/my_ssd_mobnet/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo942GN4xEQ6",
        "outputId": "58215ae4-615f-4484-e831-f251eadec397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tensorflow/workspace/models/my_ssd_mobnet/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "ayIO6zbWwmrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "LtzEqmBXxqax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVPP6Vlkyyg1",
        "outputId": "0fbbad24-3ea6-4ffd-a98e-e98160d25f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "metadata": {
        "id": "W_NF-AoSzwUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMZl_CVX0Nla",
        "outputId": "7ce4d381-dfdc-4faf-92b9-d87153cbeded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 14:14:05.386367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 14:14:05.386507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-23 14:14:05.386527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-23 14:14:09.377579: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0323 14:14:09.381409 139755813381952 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0323 14:14:09.381656 139755813381952 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0323 14:14:09.381726 139755813381952 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0323 14:14:09.381793 139755813381952 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0323 14:14:09.381898 139755813381952 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0323 14:14:09.460455 139755813381952 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0323 14:14:09.460815 139755813381952 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0323 14:14:09.460966 139755813381952 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0323 14:14:09.461055 139755813381952 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0323 14:14:09.466246 139755813381952 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0323 14:14:09.498435 139755813381952 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0323 14:14:10.528543 139755813381952 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0323 14:14:16.700854 139755813381952 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0323 14:14:18.763450 139755813381952 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "I0323 14:14:21.728827 139755813381952 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
            "I0323 14:14:21.729645 139755813381952 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 81, in main\n",
            "    model_lib_v2.eval_continuously(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py\", line 1158, in eval_continuously\n",
            "    eager_eval_loop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/object_detection/model_lib_v2.py\", line 1009, in eager_eval_loop\n",
            "    for evaluator in evaluators:\n",
            "TypeError: 'NoneType' object is not iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection import models\n",
        "cd Tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "AeOx-TUE0qkY",
        "outputId": "c4222140-42c4-480f-9f7a-06cbc550a06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-89-01606bfd5a44>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    cd Tensorflow\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "y3PZornvyllB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing cv and Libraries to show pic"
      ],
      "metadata": {
        "id": "LFKOiuUcDrDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "oa6kfDpu1Nee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "metadata": {
        "id": "i4qK8gow1SfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'cast_def_0_1828.jpeg')"
      ],
      "metadata": {
        "id": "N1ckrqXx1Unm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing an image"
      ],
      "metadata": {
        "id": "uHdVFx5dC-vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "FweUScG51XD-",
        "outputId": "13399673-af03-4468-c176-4403dd8d06f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'cast_def_0_2035.jpeg')"
      ],
      "metadata": {
        "id": "ciOry9J41yFW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}